{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T03:56:01.586418Z","iopub.execute_input":"2022-06-13T03:56:01.587980Z","iopub.status.idle":"2022-06-13T03:56:17.273727Z","shell.execute_reply.started":"2022-06-13T03:56:01.587784Z","shell.execute_reply":"2022-06-13T03:56:17.272298Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport cv2\nimport os\nfrom imutils import paths\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import backend as K\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:56:17.275782Z","iopub.execute_input":"2022-06-13T03:56:17.276186Z","iopub.status.idle":"2022-06-13T03:56:25.155038Z","shell.execute_reply.started":"2022-06-13T03:56:17.276130Z","shell.execute_reply":"2022-06-13T03:56:25.153988Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set paths to root, train, test and validation directories\n_rootDir = '../input/braintumor/Brain/'\n#os.listdir(_rootDir)\n_trainDir = _rootDir + 'train/'\n_valDir = _rootDir + 'validation/'\n_testDir = _rootDir + 'test/'","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:56:25.156264Z","iopub.execute_input":"2022-06-13T03:56:25.156850Z","iopub.status.idle":"2022-06-13T03:56:25.161022Z","shell.execute_reply.started":"2022-06-13T03:56:25.156817Z","shell.execute_reply":"2022-06-13T03:56:25.160355Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess and store images and labels\ndef load(paths, verbose=-1):\n    '''\n        return:\n            _imageList: A list of Images\n            labels: A list of corresponding Labels\n        args:\n            paths: Path to main directory \n            * Must contain images belonging to a class as a single folder\n    '''\n    _imageList = list()\n    _labelList = list()\n    \n    for (i, _imgPath) in enumerate(paths):\n        \n        img = cv2.imread(_imgPath, cv2.IMREAD_GRAYSCALE)\n        # Set the desired height and weight of image data\n        _dimensions = (32, 32)\n        \n        # resize image\n        _image = cv2.resize(img, _dimensions, interpolation = cv2.INTER_AREA)\n        numpyImage = np.array(_image).flatten()\n        \n        # rescale the image\n        mupyImage = numpyImage/255\n        label = _imgPath.split(os.path.sep)[-2]\n        #print(label)\n        \n        _imageList.append(mupyImage)\n        _labelList.append(label)\n        \n    # return a tuple of the _imageList and _labelList\n    return _imageList, _labelList","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:56:25.162506Z","iopub.execute_input":"2022-06-13T03:56:25.162887Z","iopub.status.idle":"2022-06-13T03:56:25.186287Z","shell.execute_reply.started":"2022-06-13T03:56:25.162860Z","shell.execute_reply":"2022-06-13T03:56:25.185106Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def one_hot_encoding(path):\n    _path = list(paths.list_images(path))\n    _data, _labelList = load(_path, verbose=10000)\n    _lblzr = LabelBinarizer()\n    _labels = _lblzr.fit_transform(_labelList)\n    \n    return _data, _labels","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:56:25.187675Z","iopub.execute_input":"2022-06-13T03:56:25.188151Z","iopub.status.idle":"2022-06-13T03:56:25.198926Z","shell.execute_reply.started":"2022-06-13T03:56:25.188105Z","shell.execute_reply":"2022-06-13T03:56:25.197958Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Preprocess training data\n_trainX, _trainY = one_hot_encoding(_trainDir)\n#print(len(_trainX))\n#print(type(_trainY))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:56:25.200098Z","iopub.execute_input":"2022-06-13T03:56:25.200493Z","iopub.status.idle":"2022-06-13T03:57:23.972381Z","shell.execute_reply.started":"2022-06-13T03:56:25.200462Z","shell.execute_reply":"2022-06-13T03:57:23.971393Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Preprocess validation and test data\n_valX, _valY = one_hot_encoding(_valDir)\n\n_testX, _testY = one_hot_encoding(_testDir)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:23.974418Z","iopub.execute_input":"2022-06-13T03:57:23.974870Z","iopub.status.idle":"2022-06-13T03:57:35.305468Z","shell.execute_reply.started":"2022-06-13T03:57:23.974827Z","shell.execute_reply":"2022-06-13T03:57:35.304411Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_clients(image_list, label_list, num_clients):\n    ''' return: a dictionary with keys clients' names and value as \n                data shards - tuple of images and label lists.\n        args: \n            image_list: a list of numpy arrays of training images\n            label_list:a list of binarized labels for each image\n            num_client: number of fedrated members (clients)\n            initials: the clients'name prefix, e.g, clients_1 \n            \n    '''\n\n    #create a list of client names\n    _clientNames = []\n    for i in range(num_clients):\n        _client = '{}_{}'.format('client', i+1)\n        _clientNames.append(_client)\n\n    #randomize the data\n    data = list(zip(image_list, label_list))\n    random.shuffle(data)\n\n    #shard data and place at each client\n    size = len(data)//num_clients\n    \n    _clientShards =[]\n    for i in range(0, size*num_clients, size):\n        _shard = data[i: i+size]\n        _clientShards.append(_shard)\n    \n    #number of clients must equal number of shards\n    if len(_clientShards) == len(_clientNames):\n        _clientDict = {}\n        for i in range(len(_clientNames)):\n            _clientDict[_clientNames[i]] = _clientShards[i]\n        return _clientDict\n    else:\n        return 0\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:35.306716Z","iopub.execute_input":"2022-06-13T03:57:35.307099Z","iopub.status.idle":"2022-06-13T03:57:35.318402Z","shell.execute_reply.started":"2022-06-13T03:57:35.307019Z","shell.execute_reply":"2022-06-13T03:57:35.316992Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"clients = create_clients(_trainX, _trainY, num_clients = 7)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:35.319668Z","iopub.execute_input":"2022-06-13T03:57:35.320024Z","iopub.status.idle":"2022-06-13T03:57:35.340751Z","shell.execute_reply.started":"2022-06-13T03:57:35.319994Z","shell.execute_reply":"2022-06-13T03:57:35.339687Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def batch_data(data_shard, bs=64):\n    \n    # Create tensorflow datasets from each client's data shards\n    data, label = zip(*data_shard)\n    #print(\"----------------\"+str(type(data)))\n    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n    return dataset.shuffle(len(label)).batch(bs)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:35.346289Z","iopub.execute_input":"2022-06-13T03:57:35.346937Z","iopub.status.idle":"2022-06-13T03:57:35.358862Z","shell.execute_reply.started":"2022-06-13T03:57:35.346886Z","shell.execute_reply":"2022-06-13T03:57:35.355874Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create batches for training data\nclients_batched = dict()\n\nfor (client_name, data) in clients.items():\n    clients_batched[client_name] = batch_data(data)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:35.360775Z","iopub.execute_input":"2022-06-13T03:57:35.361316Z","iopub.status.idle":"2022-06-13T03:57:36.575056Z","shell.execute_reply.started":"2022-06-13T03:57:35.361262Z","shell.execute_reply":"2022-06-13T03:57:36.573990Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#process and batch the test set  \ntest_batched = tf.data.Dataset.from_tensor_slices((_testX, _testY)).batch(len(_testY))\n\n#process and batch the test set  \nval_batched = tf.data.Dataset.from_tensor_slices((_valX, _valY)).batch(len(_valY))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:36.576454Z","iopub.execute_input":"2022-06-13T03:57:36.576905Z","iopub.status.idle":"2022-06-13T03:57:36.815682Z","shell.execute_reply.started":"2022-06-13T03:57:36.576864Z","shell.execute_reply":"2022-06-13T03:57:36.814630Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Define the hyperparameters\nlr = 0.01 \n_globalEpochs = 200\nloss='categorical_crossentropy'\nmetrics = ['accuracy'] \noptimizer = SGD(lr=lr, \n                decay=lr / _globalEpochs, \n                momentum=0.9\n               )   \nactivationFunction = \"relu\"","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:36.817159Z","iopub.execute_input":"2022-06-13T03:57:36.817535Z","iopub.status.idle":"2022-06-13T03:57:36.825777Z","shell.execute_reply.started":"2022-06-13T03:57:36.817502Z","shell.execute_reply":"2022-06-13T03:57:36.824784Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Class for model architecture\nclass MLP:\n    @staticmethod\n    def _buildModel(shape, classes):\n        model = Sequential()\n        model.add(Dense(200, input_shape=(shape,)))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(200))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(200))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(200))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(200))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n        \n        return model","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:36.827260Z","iopub.execute_input":"2022-06-13T03:57:36.827624Z","iopub.status.idle":"2022-06-13T03:57:36.839961Z","shell.execute_reply.started":"2022-06-13T03:57:36.827593Z","shell.execute_reply":"2022-06-13T03:57:36.838969Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def test_model(X_test, Y_test,  model, comm_round):\n    \n    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n    logits = model.predict(X_test)\n\n    loss = cce(Y_test, logits)\n\n    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n    print('test_acc: {:.3%} | test_loss: {}'.format(acc, loss))\n    return acc, loss","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:36.841439Z","iopub.execute_input":"2022-06-13T03:57:36.843290Z","iopub.status.idle":"2022-06-13T03:57:36.854025Z","shell.execute_reply.started":"2022-06-13T03:57:36.843239Z","shell.execute_reply":"2022-06-13T03:57:36.852878Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"central_data = tf.data.Dataset.from_tensor_slices((_trainX,_trainY)).shuffle(len(_trainY)).batch(640)\ncentral_object = MLP()\n\ncentral_model = central_object._buildModel(1024,4)\n\ncentral_model.compile(loss=loss,\n                     optimizer=optimizer,\n                     metrics=metrics)\n\ncentral_model.fit(central_data, epochs=100,verbose=0)\n\nfor(X_test,Y_test) in test_batched:\n    _acc, _loss = test_model(X_test,Y_test, central_model, 1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:57:36.855463Z","iopub.execute_input":"2022-06-13T03:57:36.855798Z","iopub.status.idle":"2022-06-13T03:58:04.448305Z","shell.execute_reply.started":"2022-06-13T03:57:36.855769Z","shell.execute_reply":"2022-06-13T03:58:04.447542Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"central_data = tf.data.Dataset.from_tensor_slices((_trainX,_trainY)).shuffle(len(_trainY)).batch(640)\ncentral_object = MLP()\n\ncentral_model = central_object._buildModel(1024,4)\n\ncentral_model.compile(loss=loss,\n                     optimizer=optimizer,\n                     metrics=metrics)\n\ncentral_model.fit(central_data, epochs=200,verbose=0)\n\nfor(X_test,Y_test) in test_batched:\n    _acc, _loss = test_model(X_test,Y_test, central_model, 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:58:04.449251Z","iopub.execute_input":"2022-06-13T03:58:04.449675Z","iopub.status.idle":"2022-06-13T03:58:47.948138Z","shell.execute_reply.started":"2022-06-13T03:58:04.449645Z","shell.execute_reply":"2022-06-13T03:58:47.946697Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}